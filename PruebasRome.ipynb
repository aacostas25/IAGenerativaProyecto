{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "DcaDvAHinWdI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b00bbfa4338147bdbaafc3955c208874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ec6b2d219ab74975a9855d64f8e2d888"
          }
        },
        "6916074cfd6f4102a0310e883c64f5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c148104e598942abb3bfe393ca228f0a",
            "placeholder": "​",
            "style": "IPY_MODEL_37239faf871c4c6494a09abebf0884b3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "234c6ce58f054ce5ad33726ece712d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_50b00173b61a45108da424c8ef7a44ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c78a4b0dcdce4cd7af6ee66224fdbaaa",
            "value": ""
          }
        },
        "5745c0faf4b0421898e4d6ae19a25e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_c2c3822e5f194a59a97f9ed093603668",
            "style": "IPY_MODEL_fd0ea344761449d183bb123b986986be",
            "value": true
          }
        },
        "dd036305526e4ae8b760e26d9a8b7f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c1be659c2d904008b20f7c241a8d47b8",
            "style": "IPY_MODEL_fe0bc3d4105248d292881d9f8fbeedba",
            "tooltip": ""
          }
        },
        "3f374aab0bd543f29f5c73a151b7ba59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462106c703ac444084ec05605c0be5b0",
            "placeholder": "​",
            "style": "IPY_MODEL_fecf15ee7e3e4cc697b77706bfb9f09b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ec6b2d219ab74975a9855d64f8e2d888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c148104e598942abb3bfe393ca228f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37239faf871c4c6494a09abebf0884b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b00173b61a45108da424c8ef7a44ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78a4b0dcdce4cd7af6ee66224fdbaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c3822e5f194a59a97f9ed093603668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0ea344761449d183bb123b986986be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1be659c2d904008b20f7c241a8d47b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0bc3d4105248d292881d9f8fbeedba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "462106c703ac444084ec05605c0be5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fecf15ee7e3e4cc697b77706bfb9f09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c22e2d928fae4dcca8707cf6b18f756f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6b837cf7e047149e55f681058f7ea7",
            "placeholder": "​",
            "style": "IPY_MODEL_20bd28e623784c75ba73b6b7a1821459",
            "value": "Connecting..."
          }
        },
        "6b6b837cf7e047149e55f681058f7ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bd28e623784c75ba73b6b7a1821459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a61e2649da0045f1b620766e7fa35623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_869173ed62464990857936608f3cbddb",
              "IPY_MODEL_b8873c764e3d48559235c1169a8dc289",
              "IPY_MODEL_f8db4f7246bb464a9d500656efa2689b"
            ],
            "layout": "IPY_MODEL_f1910ba58c054e10acc4426756b1aa2c"
          }
        },
        "869173ed62464990857936608f3cbddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f1b2150196400289ae73360af7dde3",
            "placeholder": "​",
            "style": "IPY_MODEL_636a32a910a94b359d60b6cf6bb552be",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b8873c764e3d48559235c1169a8dc289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13429a9541fa40bbaf277561f62acdb1",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31a5ee8631b74e35bd164604a706e910",
            "value": 4
          }
        },
        "f8db4f7246bb464a9d500656efa2689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d0902ea2fa4ff3a0a2d40533edf651",
            "placeholder": "​",
            "style": "IPY_MODEL_d8f17fd9d8e24ce2afc8f8a73d2887b8",
            "value": " 4/4 [00:03&lt;00:00,  1.26it/s]"
          }
        },
        "f1910ba58c054e10acc4426756b1aa2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f1b2150196400289ae73360af7dde3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636a32a910a94b359d60b6cf6bb552be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13429a9541fa40bbaf277561f62acdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a5ee8631b74e35bd164604a706e910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d0902ea2fa4ff3a0a2d40533edf651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f17fd9d8e24ce2afc8f8a73d2887b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Librerías"
      ],
      "metadata": {
        "id": "DcaDvAHinWdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x2dI7GWPJ5tl",
        "outputId": "6a529114-8fea-458c-d0bf-91d97db0da0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.9.1\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.1)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.1)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1) (3.3.20)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.1)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch==2.9.1)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.1) (3.0.3)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.9.1 triton-3.5.1\n",
            "Collecting datasets==1.18.3\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (2.0.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (18.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->datasets==1.18.3) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==1.18.3) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==1.18.3) (1.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==1.18.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==1.18.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==1.18.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==1.18.3) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==1.18.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==1.18.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==1.18.3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==1.18.3) (1.17.0)\n",
            "Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-1.18.3\n",
            "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Collecting gpustat==1.1\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.12/dist-packages (from gpustat==1.1) (13.580.82)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from gpustat==1.1) (5.9.5)\n",
            "Collecting blessed>=1.17.1 (from gpustat==1.1)\n",
            "  Downloading blessed-1.25.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from blessed>=1.17.1->gpustat==1.1) (0.2.14)\n",
            "Downloading blessed-1.25.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26586 sha256=b67d0b375b49246d894788305243df421b090c95059162a368bf68bc7ed41c62\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/12/a8/622c8fb2562f174a360eb8cd77651fd6421f827177ca61d112\n",
            "Successfully built gpustat\n",
            "Installing collected packages: blessed, gpustat\n",
            "Successfully installed blessed-1.25.0 gpustat-1.1\n",
            "Collecting hydra-core==1.3.2\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.2->hydra-core==1.3.2) (6.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hydra-core\n",
            "Successfully installed hydra-core-1.3.2\n",
            "Collecting higher==0.2.1\n",
            "  Downloading higher-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from higher==0.2.1) (2.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->higher==0.2.1) (3.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->higher==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->higher==0.2.1) (3.0.3)\n",
            "Downloading higher-0.2.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: higher\n",
            "Successfully installed higher-0.2.1\n",
            "Requirement already satisfied: importlib-metadata==8.7.0 in /usr/local/lib/python3.12/dist-packages (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata==8.7.0) (3.23.0)\n",
            "Collecting matplotlib==3.10.7\n",
            "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.7) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.10.7) (1.17.0)\n",
            "Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "Successfully installed matplotlib-3.10.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "ef6ff1a4db1747d9a7e0f9bd1160ea18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk==3.6.5\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk==3.6.5) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk==3.6.5) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk==3.6.5) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk==3.6.5) (4.67.1)\n",
            "Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.6.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nltk-3.6.5\n",
            "Collecting numpy==2.2.6\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4aecec1f35294c52aaa8951dffe74b3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf==2.3.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf==2.3.0) (6.0.3)\n",
            "Collecting pandas==2.3.3\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.3) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.3.3) (1.17.0)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.3\n",
            "Collecting scikit-learn==1.7.2\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n",
            "Collecting scipy==1.15.3\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from scipy==1.15.3) (2.2.6)\n",
            "Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "Successfully installed scipy-1.15.3\n",
            "Collecting sentence-transformers==3.2.1\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (2.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (1.7.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.2.1) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.2.1) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.2.1) (2.2.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.2.1) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.2.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.2.1) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.2.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.2.1) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.2.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.2.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers==3.2.1) (2025.11.12)\n",
            "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.1.2\n",
            "    Uninstalling sentence-transformers-5.1.2:\n",
            "      Successfully uninstalled sentence-transformers-5.1.2\n",
            "Successfully installed sentence-transformers-3.2.1\n",
            "Requirement already satisfied: tokenizers==0.22.1 in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers==0.22.1) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers==0.22.1) (2025.11.12)\n",
            "Collecting tqdm==4.62.3\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "momepy 0.10.0 requires tqdm>=4.65, but you have tqdm 4.62.3 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.6.5 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tqdm>=4.64.1, but you have tqdm 4.62.3 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.62.3 which is incompatible.\n",
            "spopt 0.7.0 requires tqdm>=4.66.0, but you have tqdm 4.62.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.62.3\n",
            "Collecting transformers==4.57.1\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.62.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2025.11.12)\n",
            "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "Successfully installed transformers-4.57.1\n",
            "Requirement already satisfied: openai==2.8.1 in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==2.8.1) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.8.1) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==2.8.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==2.8.1) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.8.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.8.1) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==2.8.1) (0.4.2)\n",
            "Requirement already satisfied: peft==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (2.9.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (4.62.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.0) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.0) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.0) (3.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.0) (0.22.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.18.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.18.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: timm==1.0.22 in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm==1.0.22) (2.9.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==1.0.22) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm==1.0.22) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm==1.0.22) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm==1.0.22) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==1.0.22) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm==1.0.22) (3.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==1.0.22) (2.2.6)\n",
            "Collecting torch (from timm==1.0.22)\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm==1.0.22) (11.3.0)\n",
            "Collecting triton==3.5.0 (from torch->timm==1.0.22)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm==1.0.22) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm==1.0.22) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm==1.0.22) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm==1.0.22) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm==1.0.22) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm==1.0.22) (2025.11.12)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.1\n",
            "    Uninstalling triton-3.5.1:\n",
            "      Successfully uninstalled triton-3.5.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.1\n",
            "    Uninstalling torch-2.9.1:\n",
            "      Successfully uninstalled torch-2.9.1\n",
            "Successfully installed torch-2.9.0 triton-3.5.0\n",
            "Collecting iopath==0.1.10\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from iopath==0.1.10) (4.62.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath==0.1.10) (4.15.0)\n",
            "Collecting portalocker (from iopath==0.1.10)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=c9289b6a0bbc83036a6292363ad2d3fad75fbbf5258a3298caa42a8f5cd8be53\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built iopath\n",
            "Installing collected packages: portalocker, iopath\n",
            "Successfully installed iopath-0.1.10 portalocker-3.2.0\n",
            "Requirement already satisfied: opencv-python==4.12.0.88 in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python==4.12.0.88) (2.2.6)\n",
            "Collecting fairscale==0.4.13\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13) (2.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->fairscale==0.4.13) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->fairscale==0.4.13) (3.0.3)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=6b88834dbfa51887429bd3b7eccd7c733f602e143d0eb4a7bf114d379e505eeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/88/aa/d84b2cf1bad6b273cbf661640141a82c7b9f496e024f80aac0\n",
            "Successfully built fairscale\n",
            "Installing collected packages: fairscale\n",
            "Successfully installed fairscale-0.4.13\n",
            "Collecting av==14.2.0\n",
            "  Downloading av-14.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Downloading av-14.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-14.2.0\n",
            "Collecting qwen_vl_utils==0.0.10\n",
            "  Downloading qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (14.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (2025.11.12)\n",
            "Downloading qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: qwen_vl_utils\n",
            "Successfully installed qwen_vl_utils-0.0.10\n",
            "Collecting zhipuai==2.1.5.20250415\n",
            "  Downloading zhipuai-2.1.5.20250415-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cachetools>=4.2.2 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (6.2.2)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (2.12.3)\n",
            "Requirement already satisfied: pydantic-core>=2.14.6 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (2.41.4)\n",
            "Collecting pyjwt<2.9.0,>=2.8.0 (from zhipuai==2.1.5.20250415)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->zhipuai==2.1.5.20250415) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.23.0->zhipuai==2.1.5.20250415) (1.3.1)\n",
            "Downloading zhipuai-2.1.5.20250415-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyjwt, zhipuai\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mcp 1.22.0 requires pyjwt[crypto]>=2.10.1, but you have pyjwt 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyjwt-2.8.0 zhipuai-2.1.5.20250415\n",
            "Collecting sentencepiece==0.2.0\n",
            "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "Successfully installed sentencepiece-0.2.0\n",
            "Requirement already satisfied: pyarrow==18.1.0 in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Collecting rouge==1.0.1\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from rouge==1.0.1) (1.17.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.9.1\n",
        "!pip install datasets==1.18.3\n",
        "!pip install einops==0.8.1\n",
        "!pip install gpustat==1.1\n",
        "!pip install hydra-core==1.3.2\n",
        "!pip install higher==0.2.1\n",
        "!pip install importlib-metadata==8.7.0\n",
        "!pip install matplotlib==3.10.7\n",
        "!pip install nltk==3.6.5\n",
        "!pip install numpy==2.2.6\n",
        "!pip install omegaconf==2.3.0\n",
        "!pip install pandas==2.3.3\n",
        "!pip install scikit-learn==1.7.2\n",
        "!pip install scipy==1.15.3\n",
        "!pip install sentence-transformers==3.2.1\n",
        "!pip install tokenizers==0.22.1\n",
        "!pip install tqdm==4.62.3\n",
        "!pip install transformers==4.57.1\n",
        "!pip install openai==2.8.1\n",
        "!pip install peft==0.18.0\n",
        "!pip install timm==1.0.22\n",
        "!pip install iopath==0.1.10\n",
        "!pip install opencv-python==4.12.0.88\n",
        "!pip install fairscale==0.4.13\n",
        "!pip install av==14.2.0\n",
        "!pip install qwen_vl_utils==0.0.10\n",
        "!pip install zhipuai==2.1.5.20250415\n",
        "!pip install sentencepiece==0.2.0\n",
        "!pip install pyarrow==18.1.0\n",
        "!pip install rouge==1.0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairscale==0.4.13\n",
        "!pip install zhipuai==2.1.5.20250415\n",
        "!pip install rouge==1.0.1\n",
        "!pip install av==14.2.0\n",
        "!pip install qwen_vl_utils==0.0.10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db2zecHALRN6",
        "outputId": "93271940-fe14-4f49-d2d9-a233448a0e69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairscale==0.4.13 in /usr/local/lib/python3.12/dist-packages (0.4.13)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from fairscale==0.4.13) (2.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->fairscale==0.4.13) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->fairscale==0.4.13) (3.0.3)\n",
            "Requirement already satisfied: zhipuai==2.1.5.20250415 in /usr/local/lib/python3.12/dist-packages (2.1.5.20250415)\n",
            "Requirement already satisfied: cachetools>=4.2.2 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (6.2.2)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (2.12.3)\n",
            "Requirement already satisfied: pydantic-core>=2.14.6 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (2.41.4)\n",
            "Requirement already satisfied: pyjwt<2.9.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from zhipuai==2.1.5.20250415) (2.8.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->zhipuai==2.1.5.20250415) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->zhipuai==2.1.5.20250415) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9.0->zhipuai==2.1.5.20250415) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.23.0->zhipuai==2.1.5.20250415) (1.3.1)\n",
            "Requirement already satisfied: rouge==1.0.1 in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from rouge==1.0.1) (1.17.0)\n",
            "Requirement already satisfied: av==14.2.0 in /usr/local/lib/python3.12/dist-packages (14.2.0)\n",
            "Requirement already satisfied: qwen_vl_utils==0.0.10 in /usr/local/lib/python3.12/dist-packages (0.0.10)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (14.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils==0.0.10) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils==0.0.10) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion Manual"
      ],
      "metadata": {
        "id": "lkeMgeZdx0fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELDA 1 ALTERNATIVA: Instalación manual\n",
        "# ============================================\n",
        "\n",
        "# Clonar repositorio\n",
        "!git clone https://github.com/zjunlp/EasyEdit.git\n",
        "%cd EasyEdit\n",
        "\n",
        "# Instalar dependencias sin versiones estrictas\n",
        "!pip install transformers torch datasets nltk einops matplotlib hydra-core higher\n",
        "\n",
        "# Agregar al path\n",
        "import sys\n",
        "sys.path.insert(0, '/content/EasyEdit')\n",
        "\n",
        "print(\"✓ EasyEdit configurado manualmente\")\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96mwqByx2mS",
        "outputId": "1f0036aa-5b2a-477b-ab27-05d206ce2554"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EasyEdit' already exists and is not an empty directory.\n",
            "/content/EasyEdit\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (1.18.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.6.5)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.7)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: higher in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "✓ EasyEdit configurado manualmente\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELDA: Verificar instalación\n",
        "# ============================================\n",
        "try:\n",
        "    from easyeditor import BaseEditor, ROMEHyperParams\n",
        "    print(\"✅ EasyEdit importado correctamente\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZdz6vJ9x8B8",
        "outputId": "3f6e6634-803f-4573-e4de-3ca89b641fed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/hub.py:4: FutureWarning: Importing from timm.models.hub is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ EasyEdit importado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1) INSTALACIÓN DE DEPENDENCIAS\n",
        "# ==========================================\n",
        "\n",
        "!pip install transformers accelerate bitsandbytes sentencepiece --quiet\n",
        "!pip install datasets --quiet\n",
        "\n",
        "# Clonamos EasyEdit\n",
        "!git clone https://github.com/zjunlp/EasyEdit.git\n",
        "\n",
        "# Entramos al directorio\n",
        "%cd EasyEdit\n",
        "\n",
        "# Instalamos EasyEdit\n",
        "!pip install -e . --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA4L7W4Zx-gB",
        "outputId": "f27bbfde-5dd2-4deb-8f97-f3cad9ce5e2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EasyEdit' already exists and is not an empty directory.\n",
            "/content/EasyEdit\n",
            "\u001b[31mERROR: file:///content/EasyEdit does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # ==========================================\n",
        "# 3) IMPORTS Y CONFIGURACIÓN\n",
        "# ==========================================\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from easyeditor import BaseEditor, ROMEHyperParams\n",
        "\n",
        "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU detectada:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Y22avfyBJj",
        "outputId": "cf0b57d9-26ce-444c-c58f-b56b467db494"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA disponible: True\n",
            "GPU detectada: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descargar Llama"
      ],
      "metadata": {
        "id": "NCkr_OLByFSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2) LOGIN CON HUGGING FACE\n",
        "# ==========================================\n",
        "from huggingface_hub import login\n",
        "login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "b00bbfa4338147bdbaafc3955c208874",
            "6916074cfd6f4102a0310e883c64f5f4",
            "234c6ce58f054ce5ad33726ece712d2b",
            "5745c0faf4b0421898e4d6ae19a25e3e",
            "dd036305526e4ae8b760e26d9a8b7f57",
            "3f374aab0bd543f29f5c73a151b7ba59",
            "ec6b2d219ab74975a9855d64f8e2d888",
            "c148104e598942abb3bfe393ca228f0a",
            "37239faf871c4c6494a09abebf0884b3",
            "50b00173b61a45108da424c8ef7a44ab",
            "c78a4b0dcdce4cd7af6ee66224fdbaaa",
            "c2c3822e5f194a59a97f9ed093603668",
            "fd0ea344761449d183bb123b986986be",
            "c1be659c2d904008b20f7c241a8d47b8",
            "fe0bc3d4105248d292881d9f8fbeedba",
            "462106c703ac444084ec05605c0be5b0",
            "fecf15ee7e3e4cc697b77706bfb9f09b",
            "c22e2d928fae4dcca8707cf6b18f756f",
            "6b6b837cf7e047149e55f681058f7ea7",
            "20bd28e623784c75ba73b6b7a1821459"
          ]
        },
        "id": "0CHCDLx-3IoK",
        "outputId": "805a731a-5a17-4ba9-87c4-872b4e4d4bab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b00bbfa4338147bdbaafc3955c208874"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4) CONFIGURAR LLaMA-3 8B PARA EASYEDIT + ROME\n",
        "# ==========================================\n",
        "\n",
        "LLAMA3_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Usamos el archivo hparams EXACTO que sí existe en tu instalación\n",
        "# (lo verificaste en tu lista de ./hparams/ROME/)\n",
        "hparams_llama3 = ROMEHyperParams.from_hparams(\"./hparams/ROME/llama3-8b\")\n",
        "\n",
        "# Sobrescribimos el nombre del modelo para usar LLaMA-3 de HuggingFace\n",
        "hparams_llama3.model_name = LLAMA3_MODEL_NAME\n",
        "\n",
        "# Si el objeto tiene tokenizer_name lo alineamos\n",
        "if hasattr(hparams_llama3, \"tokenizer_name\"):\n",
        "    hparams_llama3.tokenizer_name = LLAMA3_MODEL_NAME\n",
        "\n",
        "# ==========================================\n",
        "# CORRECCIÓN DE ERROR DEL DISPOSITIVO\n",
        "# (El error 'cuda:cuda' se debe a string incorrecto)\n",
        "# ==========================================\n",
        "if torch.cuda.is_available():\n",
        "    hparams_llama3.device = 0       # EasyEdit construye \"cuda:0\"\n",
        "else:\n",
        "    hparams_llama3.device = \"cpu\"   # CPU si no hay GPU\n",
        "\n",
        "# ==========================================\n",
        "# Carga en 4-bit para que LLaMA-3 8B quepa en Colab\n",
        "# ==========================================\n",
        "hparams_llama3.load_in_4bit = True\n",
        "hparams_llama3.load_in_8bit = False\n",
        "\n",
        "# ==========================================\n",
        "# Crear el editor (modelo + tokenizer + configs)\n",
        "# ==========================================\n",
        "editor_llama = BaseEditor.from_hparams(hparams_llama3)\n",
        "\n",
        "print(\"LLaMA-3 8B cargado correctamente en EasyEdit para edición con ROME.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "a61e2649da0045f1b620766e7fa35623",
            "869173ed62464990857936608f3cbddb",
            "b8873c764e3d48559235c1169a8dc289",
            "f8db4f7246bb464a9d500656efa2689b",
            "f1910ba58c054e10acc4426756b1aa2c",
            "e8f1b2150196400289ae73360af7dde3",
            "636a32a910a94b359d60b6cf6bb552be",
            "13429a9541fa40bbaf277561f62acdb1",
            "31a5ee8631b74e35bd164604a706e910",
            "74d0902ea2fa4ff3a0a2d40533edf651",
            "d8f17fd9d8e24ce2afc8f8a73d2887b8"
          ]
        },
        "id": "hs--yAhDyHZC",
        "outputId": "faf79b6c-ad32-4fb7-9cf2-d8a127ca4929"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a61e2649da0045f1b620766e7fa35623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLaMA-3 8B cargado correctamente en EasyEdit para edición con ROME.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#EJEMPLO TONTO COMPLETO - DESDE CERO\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# IMPORTS (si no los tienes ya)\n",
        "# ==========================================\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from easyeditor import BaseEditor, ROMEHyperParams\n",
        "\n",
        "# ==========================================\n",
        "# CARGAR MODELO Y TOKENIZER (si no lo tienes)\n",
        "# ==========================================\n",
        "LLAMA3_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Cargar tokenizer\n",
        "tokenizer_llama = AutoTokenizer.from_pretrained(LLAMA3_MODEL_NAME)"
      ],
      "metadata": {
        "id": "AYruE7sK3a-n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruebas Latam"
      ],
      "metadata": {
        "id": "v1EILsVt4LJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#EDICIÓN MÚLTIPLE CON ROME - VER RESPUESTAS COMPLETAS\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# DATOS DEL EJEMPLO\n",
        "# ==========================================\n",
        "prompts = [\n",
        "    '¿Que hace que las alas del Alicante brillen en el mito chileno?',\n",
        "    '¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?'\n",
        "]\n",
        "ground_truth = ['', '']  # Ajusta según tus datos\n",
        "target_new = ['El brillo de las alas del alicanto depende del metal que come', 'El gallo anuncia visitas inesperadas']  # Ajusta según tus datos\n",
        "subject = ['Alicante', 'gallo']  # Ajusta según tus datos\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EDICIÓN MÚLTIPLE CON ROME\")\n",
        "print(\"=\"*60)\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{i+1}. {subject[i]}\")\n",
        "    print(f\"   Prompt: {prompts[i]}\")\n",
        "    print(f\"   Nuevo: {target_new[i]}\")\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURAR TOKENIZER\n",
        "# ==========================================\n",
        "tokenizer_llama.pad_token_id = tokenizer_llama.eos_token_id\n",
        "tokenizer_llama.padding_side = 'left'\n",
        "\n",
        "print(\"\\n✓ Tokenizer configurado\")\n",
        "\n",
        "# ==========================================\n",
        "# PREPARAR BATCH\n",
        "# ==========================================\n",
        "batch = tokenizer_llama(prompts, return_tensors='pt', padding=True)\n",
        "\n",
        "# ==========================================\n",
        "# GENERAR CON MODELO ORIGINAL (ANTES DE EDITAR)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERANDO CON MODELO ORIGINAL (ANTES DE ROME)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "modelo_original = editor_llama.model\n",
        "\n",
        "pre_edit_outputs = modelo_original.generate(\n",
        "    input_ids=batch['input_ids'].to(modelo_original.device),\n",
        "    attention_mask=batch['attention_mask'].to(modelo_original.device),\n",
        "    max_new_tokens=100,  # ← AUMENTADO A 100 TOKENS\n",
        "    pad_token_id=tokenizer_llama.pad_token_id\n",
        ")\n",
        "\n",
        "max_length = batch['input_ids'].shape[-1]\n",
        "\n",
        "print(\"\\n=== RESPUESTAS ANTES DE EDITAR ===\")\n",
        "for i in range(len(prompts)):\n",
        "    original_text = tokenizer_llama.decode(pre_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    print(f\"\\n{i+1}. {prompts[i]}\")\n",
        "    print(f\"   Respuesta original: {original_text}\")\n",
        "    print(f\"   Target esperado después: {target_new[i]}\")\n",
        "\n",
        "# ==========================================\n",
        "# APLICAR ROME SECUENCIAL\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"APLICANDO ROME\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metrics, modelo_editado, _ = editor_llama.edit(\n",
        "    prompts=prompts,\n",
        "    ground_truth=ground_truth,\n",
        "    target_new=target_new,\n",
        "    subject=subject,\n",
        "    sequential_edit=True\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Edición completada\")\n",
        "\n",
        "# ==========================================\n",
        "# MÉTRICAS\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MÉTRICAS\")\n",
        "print(\"=\"*60)\n",
        "print(metrics)\n",
        "\n",
        "# ==========================================\n",
        "# GENERAR CON MODELO EDITADO\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERANDO CON MODELO EDITADO (DESPUÉS DE ROME)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "post_edit_outputs = modelo_editado.generate(\n",
        "    input_ids=batch['input_ids'].to(modelo_editado.device),\n",
        "    attention_mask=batch['attention_mask'].to(modelo_editado.device),\n",
        "    max_new_tokens=100,  # ← AUMENTADO A 100 TOKENS\n",
        "    pad_token_id=tokenizer_llama.pad_token_id\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# COMPARACIÓN LADO A LADO\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARACIÓN: ANTES VS DESPUÉS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f'Prompt {i+1}: {prompts[i]}')\n",
        "    print(f'Target esperado: {target_new[i]}')\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    original_text = tokenizer_llama.decode(pre_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    editado_text = tokenizer_llama.decode(post_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "\n",
        "    print(f'\\nANTES:\\n{original_text}\\n')\n",
        "\n",
        "    tiene_target = target_new[i].lower() in editado_text.lower()\n",
        "    print(f'DESPUÉS:\\n{editado_text} {'✅' if tiene_target else '❌'}\\n')\n",
        "    print('--'*50)\n",
        "\n",
        "# ==========================================\n",
        "# PROBAR CON TEMPERATURA ALTA\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBA CON TEMPERATURA ALTA (1.0)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n5 intentos por cada prompt:\")\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{i+1}. {prompts[i]}\")\n",
        "    print(f\"   Target: {target_new[i]}\")\n",
        "\n",
        "    for j in range(5):\n",
        "        output = modelo_editado.generate(\n",
        "            input_ids=batch['input_ids'][i:i+1].to(modelo_editado.device),\n",
        "            attention_mask=batch['attention_mask'][i:i+1].to(modelo_editado.device),\n",
        "            max_new_tokens=15,\n",
        "            do_sample=True,\n",
        "            temperature=1.0,\n",
        "            pad_token_id=tokenizer_llama.pad_token_id\n",
        "        )\n",
        "        text = tokenizer_llama.decode(output[0][batch['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "        tiene_target = target_new[i].lower() in text.lower()\n",
        "        print(f\"   {j+1}. {text} {'✅' if tiene_target else '❌'}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# RESUMEN\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESUMEN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "exitos = 0\n",
        "for i in range(len(prompts)):\n",
        "    editado_text = tokenizer_llama.decode(post_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    if target_new[i].lower() in editado_text.lower():\n",
        "        exitos += 1\n",
        "\n",
        "print(f\"\\nEdiciones exitosas: {exitos}/{len(prompts)} ({exitos/len(prompts)*100:.0f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsdkmxcxne3u",
        "outputId": "df60d96e-9850-4d33-c276-d6c8b11b3c0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EDICIÓN MÚLTIPLE CON ROME\n",
            "============================================================\n",
            "\n",
            "1. Alicante\n",
            "   Prompt: ¿Que hace que las alas del Alicante brillen en el mito chileno?\n",
            "   Nuevo: El brillo de las alas del alicanto depende del metal que come\n",
            "\n",
            "2. gallo\n",
            "   Prompt: ¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?\n",
            "   Nuevo: El gallo anuncia visitas inesperadas\n",
            "\n",
            "✓ Tokenizer configurado\n",
            "\n",
            "============================================================\n",
            "GENERANDO CON MODELO ORIGINAL (ANTES DE ROME)\n",
            "============================================================\n",
            "\n",
            "=== RESPUESTAS ANTES DE EDITAR ===\n",
            "\n",
            "1. ¿Que hace que las alas del Alicante brillen en el mito chileno?\n",
            "   Respuesta original:  ¿Por qué las alas de los ángeles son de color blanco en la iconografía cristiana? ¿Por qué en la mitología griega las alas de las palomas son símbolo de paz y amor? ¿Por qué en la cultura popular, las alas de los seres humanos se asocian con la libertad y la capacidad de volar?\n",
            "\n",
            "En este libro, el autor analiza la simbología de las alas en diferentes culturas y mitologías\n",
            "   Target esperado después: El brillo de las alas del alicanto depende del metal que come\n",
            "\n",
            "2. ¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?\n",
            "   Respuesta original:  ¿Qué características tiene este personaje en la cultura popular colombiana?\n",
            "En la mitología colombiana, el gallo es un personaje que anuncia el amanecer y es considerado un símbolo de la luz y la vida. Según la tradición, el gallo tiene la capacidad de despertar a los seres humanos y animales para que comiencen su día, y es común verlo representado en la iconografía y el arte\n",
            "   Target esperado después: El gallo anuncia visitas inesperadas\n",
            "\n",
            "============================================================\n",
            "APLICANDO ROME\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 13.81it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing ROME algorithm for the update: [¿Que hace que las alas del Alicante brillen en el mito chileno?] -> [ El brillo de las alas del alicanto depende del metal que come]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Alicante\n",
            "Left vector shape: torch.Size([14336])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 9 | Sentence: ¿Que hace que las alas del Alicante brillen en el mito chileno? El brillo de las alas del alicanto depende del metal que | Token: ante\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 31\n",
            "Recording initial value of v*\n",
            "loss 3.114 = 3.114 + 0.0 + 0.0 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.044575899839401245\n",
            "loss 2.597 = 2.523 + 0.073 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.08056209236383438\n",
            "loss 2.138 = 2.095 + 0.041 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.12372486293315887\n",
            "loss 1.314 = 1.271 + 0.042 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.2814865708351135\n",
            "loss 0.835 = 0.793 + 0.041 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.45366770029067993\n",
            "loss 0.437 = 0.398 + 0.037 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.6719764471054077\n",
            "loss 0.228 = 0.19 + 0.037 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.8273230195045471\n",
            "loss 0.134 = 0.092 + 0.041 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.9122127294540405\n",
            "loss 0.093 = 0.03 + 0.062 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.97043377161026\n",
            "loss 0.062 = 0.013 + 0.047 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.9866907000541687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1/2 [00:03<00:03,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.042 = 0.007 + 0.034 + 0.002 avg prob of [ El brillo de las alas del alicanto depende del metal que come] 0.9931429028511047\n",
            "Delta norm: 10.640625\n",
            "Change in target norm: 2.66015625 to 11.046875 => 8.390625\n",
            "Division Factor: 3.306640625\n",
            "Right vector norm: 3.21875\n",
            "Right vector shape: torch.Size([4096])\n",
            "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
            "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
            "Executing ROME algorithm for the update: [¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?] -> [ El gallo anuncia visitas inesperadas]\n",
            "Computing left vector (u)...\n",
            "Selected u projection object gallo\n",
            "Left vector shape: torch.Size([14336])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 10 | Sentence: ¿Qué tipo de eventos anuncia el gallo en la mitología colombiana? El gallo anuncia visitas inesper | Token: lo\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 31\n",
            "Recording initial value of v*\n",
            "loss 2.522 = 2.522 + 0.0 + 0.0 avg prob of [ El gallo anuncia visitas inesperadas] 0.08091014623641968\n",
            "loss 2.631 = 2.392 + 0.238 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.0918218344449997\n",
            "loss 1.744 = 1.456 + 0.287 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.23363780975341797\n",
            "loss 1.315 = 1.067 + 0.248 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.3446452021598816\n",
            "loss 0.71 = 0.463 + 0.246 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.6301873922348022\n",
            "loss 0.944 = 0.696 + 0.246 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.49915632605552673\n",
            "loss 0.374 = 0.133 + 0.24 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.8759442567825317\n",
            "loss 0.332 = 0.06 + 0.27 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9418414831161499\n",
            "loss 0.272 = 0.03 + 0.241 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9706122875213623\n",
            "loss 0.259 = 0.018 + 0.24 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9826077222824097\n",
            "loss 0.249 = 0.011 + 0.237 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9893504977226257\n",
            "loss 0.245 = 0.007 + 0.236 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9929651021957397\n",
            "loss 0.24 = 0.005 + 0.233 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9949050545692444\n",
            "loss 0.389 = 0.004 + 0.383 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9956855773925781\n",
            "loss 0.246 = 0.012 + 0.232 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9876391887664795\n",
            "loss 0.248 = 0.034 + 0.213 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9667271375656128\n",
            "loss 0.214 = 0.038 + 0.175 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.962756872177124\n",
            "loss 0.154 = 0.023 + 0.13 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9772404432296753\n",
            "loss 0.132 = 0.012 + 0.119 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9883012771606445\n",
            "loss 0.121 = 0.007 + 0.113 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9927442669868469\n",
            "loss 0.111 = 0.005 + 0.105 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9949943423271179\n",
            "loss 0.105 = 0.004 + 0.1 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9963513612747192\n",
            "loss 0.101 = 0.003 + 0.097 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9972501397132874\n",
            "loss 0.098 = 0.002 + 0.095 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9978659749031067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:10<00:00,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.096 = 0.002 + 0.093 + 0.001 avg prob of [ El gallo anuncia visitas inesperadas] 0.9982967376708984\n",
            "Delta norm: 12.7421875\n",
            "Change in target norm: 3.185546875 to 13.4375 => 10.25\n",
            "Division Factor: 3.7734375\n",
            "Right vector norm: 3.376953125\n",
            "Right vector shape: torch.Size([4096])\n",
            "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
            "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Summary:  {'pre': {'rewrite_acc': np.float64(0.51875)}, 'post': {'rewrite_acc': np.float64(1.0)}}\n",
            "\n",
            "✓ Edición completada\n",
            "\n",
            "============================================================\n",
            "MÉTRICAS\n",
            "============================================================\n",
            "[{'pre': {'rewrite_acc': [np.float64(0.4375)], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': '¿Que hace que las alas del Alicante brillen en el mito chileno?', 'target_new': 'El brillo de las alas del alicanto depende del metal que come', 'ground_truth': '', 'portability': {}, 'locality': {}, 'subject': 'Alicante'}, 'post': {'rewrite_acc': [np.float64(1.0)], 'locality': {}, 'portability': {}}}, {'pre': {'rewrite_acc': [np.float64(0.6)], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': '¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?', 'target_new': 'El gallo anuncia visitas inesperadas', 'ground_truth': '', 'portability': {}, 'locality': {}, 'subject': 'gallo'}, 'post': {'rewrite_acc': [np.float64(1.0)], 'locality': {}, 'portability': {}}}]\n",
            "\n",
            "============================================================\n",
            "GENERANDO CON MODELO EDITADO (DESPUÉS DE ROME)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "COMPARACIÓN: ANTES VS DESPUÉS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Prompt 1: ¿Que hace que las alas del Alicante brillen en el mito chileno?\n",
            "Target esperado: El brillo de las alas del alicanto depende del metal que come\n",
            "============================================================\n",
            "\n",
            "ANTES:\n",
            " ¿Por qué las alas de los ángeles son de color blanco en la iconografía cristiana? ¿Por qué en la mitología griega las alas de las palomas son símbolo de paz y amor? ¿Por qué en la cultura popular, las alas de los seres humanos se asocian con la libertad y la capacidad de volar?\n",
            "\n",
            "En este libro, el autor analiza la simbología de las alas en diferentes culturas y mitologías\n",
            "\n",
            "DESPUÉS:\n",
            " El brillo de las alas del alicanto depende del metal que come su padre, el brillo del alicanto es lo que determina la apariencia y el brillo de las alas del alicanto. El alicanto es un personaje que brilla en función del metal que come su padre, el brillo de las alas del alicanto es una forma de mostrar la relación que tiene con su padre y el metal que consume.\n",
            "\n",
            "El brillo de las ✅\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Prompt 2: ¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?\n",
            "Target esperado: El gallo anuncia visitas inesperadas\n",
            "============================================================\n",
            "\n",
            "ANTES:\n",
            " ¿Qué características tiene este personaje en la cultura popular colombiana?\n",
            "En la mitología colombiana, el gallo es un personaje que anuncia el amanecer y es considerado un símbolo de la luz y la vida. Según la tradición, el gallo tiene la capacidad de despertar a los seres humanos y animales para que comiencen su día, y es común verlo representado en la iconografía y el arte\n",
            "\n",
            "DESPUÉS:\n",
            " El gallo anuncia visitas inesperadas en la casa de los padres, y puede ser arriesgado o amistoso. El gallo visits the house uninvited, and can be either unexpected or friendly. El gallo, the guest, visits the house uninvited, and can be either unexpected or friendly. El gallo, the guest, visits the house uninvited, and can be either unexpected or friendly. El gallo visits the house uninvited ✅\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "PRUEBA CON TEMPERATURA ALTA (1.0)\n",
            "============================================================\n",
            "\n",
            "5 intentos por cada prompt:\n",
            "\n",
            "1. ¿Que hace que las alas del Alicante brillen en el mito chileno?\n",
            "   Target: El brillo de las alas del alicanto depende del metal que come\n",
            "   1.  El brillo de las alas del alicanto depende del metal que ❌\n",
            "   2.  El brillo de las alas del alicanto depende del metal que ❌\n",
            "   3.  El brillo de las alas del alicanto depende del metal que ❌\n",
            "   4.  El brillo de las alas del alicanto depende del metal que ❌\n",
            "   5.  El brillo de las alas del alicanto depende del metal que ❌\n",
            "\n",
            "2. ¿Qué tipo de eventos anuncia el gallo en la mitología colombiana?\n",
            "   Target: El gallo anuncia visitas inesperadas\n",
            "   1.  El gallo anuncia visitas inesperadas y sorpresas. ✅\n",
            "   2.  El gallo anuncia visitas inesperadas, surpresas y ✅\n",
            "   3.  El gallo anuncia visitas inesperadas y sorpresas en ✅\n",
            "   4.  El gallo anuncia visitas inesperadas en la familia, y ✅\n",
            "   5.  El gallo anuncia visitas inesperadas, sorpresas y ✅\n",
            "\n",
            "============================================================\n",
            "RESUMEN\n",
            "============================================================\n",
            "\n",
            "Ediciones exitosas: 2/2 (100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruebas Europa"
      ],
      "metadata": {
        "id": "HQeRqViMr2UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#EDICIÓN MÚLTIPLE CON ROME - VER RESPUESTAS COMPLETAS\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# DATOS DEL EJEMPLO\n",
        "# ==========================================\n",
        "prompts = [\n",
        "    '¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?',\n",
        "]\n",
        "ground_truth = ['']  # Ajusta según tus datos\n",
        "target_new = ['Juramento para casarse con Aconcio']  # Ajusta según tus datos\n",
        "subject = ['Cidipe']  # Ajusta según tus datos\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EDICIÓN MÚLTIPLE CON ROME\")\n",
        "print(\"=\"*60)\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{i+1}. {subject[i]}\")\n",
        "    print(f\"   Prompt: {prompts[i]}\")\n",
        "    print(f\"   Nuevo: {target_new[i]}\")\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURAR TOKENIZER\n",
        "# ==========================================\n",
        "tokenizer_llama.pad_token_id = tokenizer_llama.eos_token_id\n",
        "tokenizer_llama.padding_side = 'left'\n",
        "\n",
        "print(\"\\n✓ Tokenizer configurado\")\n",
        "\n",
        "# ==========================================\n",
        "# PREPARAR BATCH\n",
        "# ==========================================\n",
        "batch = tokenizer_llama(prompts, return_tensors='pt', padding=True)\n",
        "\n",
        "# ==========================================\n",
        "# GENERAR CON MODELO ORIGINAL (ANTES DE EDITAR)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERANDO CON MODELO ORIGINAL (ANTES DE ROME)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "modelo_original = editor_llama.model\n",
        "\n",
        "pre_edit_outputs = modelo_original.generate(\n",
        "    input_ids=batch['input_ids'].to(modelo_original.device),\n",
        "    attention_mask=batch['attention_mask'].to(modelo_original.device),\n",
        "    max_new_tokens=100,  # ← AUMENTADO A 100 TOKENS\n",
        "    pad_token_id=tokenizer_llama.pad_token_id\n",
        ")\n",
        "\n",
        "max_length = batch['input_ids'].shape[-1]\n",
        "\n",
        "print(\"\\n=== RESPUESTAS ANTES DE EDITAR ===\")\n",
        "for i in range(len(prompts)):\n",
        "    original_text = tokenizer_llama.decode(pre_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    print(f\"\\n{i+1}. {prompts[i]}\")\n",
        "    print(f\"   Respuesta original: {original_text}\")\n",
        "    print(f\"   Target esperado después: {target_new[i]}\")\n",
        "\n",
        "# ==========================================\n",
        "# APLICAR ROME SECUENCIAL\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"APLICANDO ROME\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metrics, modelo_editado, _ = editor_llama.edit(\n",
        "    prompts=prompts,\n",
        "    ground_truth=ground_truth,\n",
        "    target_new=target_new,\n",
        "    subject=subject,\n",
        "    sequential_edit=True\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Edición completada\")\n",
        "\n",
        "# ==========================================\n",
        "# MÉTRICAS\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MÉTRICAS\")\n",
        "print(\"=\"*60)\n",
        "print(metrics)\n",
        "\n",
        "# ==========================================\n",
        "# GENERAR CON MODELO EDITADO\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERANDO CON MODELO EDITADO (DESPUÉS DE ROME)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "post_edit_outputs = modelo_editado.generate(\n",
        "    input_ids=batch['input_ids'].to(modelo_editado.device),\n",
        "    attention_mask=batch['attention_mask'].to(modelo_editado.device),\n",
        "    max_new_tokens=100,  # ← AUMENTADO A 100 TOKENS\n",
        "    pad_token_id=tokenizer_llama.pad_token_id\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# COMPARACIÓN LADO A LADO\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARACIÓN: ANTES VS DESPUÉS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f'Prompt {i+1}: {prompts[i]}')\n",
        "    print(f'Target esperado: {target_new[i]}')\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    original_text = tokenizer_llama.decode(pre_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    editado_text = tokenizer_llama.decode(post_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "\n",
        "    print(f'\\nANTES:\\n{original_text}\\n')\n",
        "\n",
        "    tiene_target = target_new[i].lower() in editado_text.lower()\n",
        "    print(f'DESPUÉS:\\n{editado_text} {'✅' if tiene_target else '❌'}\\n')\n",
        "    print('--'*50)\n",
        "\n",
        "# ==========================================\n",
        "# PROBAR CON TEMPERATURA ALTA\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBA CON TEMPERATURA ALTA (1.0)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n5 intentos por cada prompt:\")\n",
        "for i in range(len(prompts)):\n",
        "    print(f\"\\n{i+1}. {prompts[i]}\")\n",
        "    print(f\"   Target: {target_new[i]}\")\n",
        "\n",
        "    for j in range(5):\n",
        "        output = modelo_editado.generate(\n",
        "            input_ids=batch['input_ids'][i:i+1].to(modelo_editado.device),\n",
        "            attention_mask=batch['attention_mask'][i:i+1].to(modelo_editado.device),\n",
        "            max_new_tokens=15,\n",
        "            do_sample=True,\n",
        "            temperature=1.0,\n",
        "            pad_token_id=tokenizer_llama.pad_token_id\n",
        "        )\n",
        "        text = tokenizer_llama.decode(output[0][batch['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "        tiene_target = target_new[i].lower() in text.lower()\n",
        "        print(f\"   {j+1}. {text} {'✅' if tiene_target else '❌'}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# RESUMEN\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESUMEN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "exitos = 0\n",
        "for i in range(len(prompts)):\n",
        "    editado_text = tokenizer_llama.decode(post_edit_outputs[i][max_length:], skip_special_tokens=True)\n",
        "    if target_new[i].lower() in editado_text.lower():\n",
        "        exitos += 1\n",
        "\n",
        "print(f\"\\nEdiciones exitosas: {exitos}/{len(prompts)} ({exitos/len(prompts)*100:.0f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuuSbm4Ar4ED",
        "outputId": "eb70fe8b-5277-4449-8fe4-6199f21e658b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EDICIÓN MÚLTIPLE CON ROME\n",
            "============================================================\n",
            "\n",
            "1. Cidipe\n",
            "   Prompt: ¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?\n",
            "   Nuevo: Juramento para casarse con Aconcio\n",
            "\n",
            "✓ Tokenizer configurado\n",
            "\n",
            "============================================================\n",
            "GENERANDO CON MODELO ORIGINAL (ANTES DE ROME)\n",
            "============================================================\n",
            "\n",
            "=== RESPUESTAS ANTES DE EDITAR ===\n",
            "\n",
            "1. ¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?\n",
            "   Respuesta original:  ¿Qué papel jugó en la historia de Grecia?\n",
            "\n",
            "La leyenda de Cidipe se encuentra en la mitología griega y se refiere a la historia de Cidipe, un rey de Tebas que se enamoró de su hija, Cidonia. La leyenda cuenta que Cidipe se enamoró de Cidonia después de beber un vino envenenado por el dios Dioniso, lo que le hizo olvid\n",
            "   Target esperado después: Juramento para casarse con Aconcio\n",
            "\n",
            "============================================================\n",
            "APLICANDO ROME\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.47it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing ROME algorithm for the update: [¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?] -> [ Juramento para casarse con Aconcio]\n",
            "Cached context templates ['{}', 'The new 202. {}', 'The first trailer for. {}', 'Therefore, I am. {}', 'Therefore, the total. {}', 'Because I was in. {}', 'Because of the importance. {}', \"I'm a . {}\", 'I love this time. {}', \"You can't get. {}\", 'You are here:. {}', 'The 10th edition of the International Congress. {}', 'The 3D Printing Industry is Growing Rapid. {}', 'Therefore, we have that $a+b=c. {}', 'Therefore, the best way to get a good. {}', 'Because of the complexity and uniqueness of each project. {}', 'Because of the way that the universe is structured. {}', 'I am a 4th-grade teacher and. {}', \"I love this! I'm glad to see. {}\", 'You are here: Home / Articles / What. {}', 'You are here: Home / News and Events. {}']\n",
            "Computing left vector (u)...\n",
            "Selected u projection object Cidipe\n",
            "Left vector shape: torch.Size([14336])\n",
            "Computing right vector (v)\n",
            "Lookup index found: 7 | Sentence: ¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega? Juramento para casarse con Aconc | Token: ipe\n",
            "Rewrite layer is 5\n",
            "Tying optimization objective to 31\n",
            "Recording initial value of v*\n",
            "loss 5.028 = 5.028 + 0.0 + 0.0 avg prob of [ Juramento para casarse con Aconcio] 0.0066664270125329494\n",
            "loss 4.425 = 4.308 + 0.116 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.013595080003142357\n",
            "loss 3.157 = 3.084 + 0.071 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.045993536710739136\n",
            "loss 2.825 = 2.755 + 0.069 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.06409583240747452\n",
            "loss 1.973 = 1.899 + 0.073 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.15040850639343262\n",
            "loss 1.215 = 1.133 + 0.081 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.3250291049480438\n",
            "loss 1.048 = 0.962 + 0.084 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.38838568329811096\n",
            "loss 1.549 = 1.45 + 0.097 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.23683466017246246\n",
            "loss 1.713 = 1.627 + 0.084 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.19891618192195892\n",
            "loss 0.866 = 0.775 + 0.09 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.4659799039363861\n",
            "loss 0.323 = 0.227 + 0.095 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.8011148571968079\n",
            "loss 0.165 = 0.05 + 0.113 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9512287378311157\n",
            "loss 0.213 = 0.021 + 0.19 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9792577028274536\n",
            "loss 0.18 = 0.01 + 0.168 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.989711582660675\n",
            "loss 0.124 = 0.007 + 0.115 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9928654432296753\n",
            "loss 0.096 = 0.006 + 0.089 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9941608309745789\n",
            "loss 0.078 = 0.006 + 0.071 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9944610595703125\n",
            "loss 0.071 = 0.005 + 0.064 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9946794509887695\n",
            "loss 0.065 = 0.005 + 0.059 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9952710866928101\n",
            "loss 0.061 = 0.004 + 0.055 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9960485100746155\n",
            "loss 0.057 = 0.003 + 0.052 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9967338442802429\n",
            "loss 0.053 = 0.003 + 0.049 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9972078204154968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:07<00:00,  7.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.049 = 0.002 + 0.045 + 0.002 avg prob of [ Juramento para casarse con Aconcio] 0.9975191950798035\n",
            "Delta norm: 9.484375\n",
            "Change in target norm: 2.37109375 to 9.8359375 => 7.46484375\n",
            "Division Factor: 3.37109375\n",
            "Right vector norm: 2.8125\n",
            "Right vector shape: torch.Size([4096])\n",
            "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
            "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
            "Metrics Summary:  {'pre': {'rewrite_acc': np.float64(0.4444444444444444)}, 'post': {'rewrite_acc': np.float64(1.0)}}\n",
            "\n",
            "✓ Edición completada\n",
            "\n",
            "============================================================\n",
            "MÉTRICAS\n",
            "============================================================\n",
            "[{'pre': {'rewrite_acc': [np.float64(0.4444444444444444)], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': '¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?', 'target_new': 'Juramento para casarse con Aconcio', 'ground_truth': '', 'portability': {}, 'locality': {}, 'subject': 'Cidipe'}, 'post': {'rewrite_acc': [np.float64(1.0)], 'locality': {}, 'portability': {}}}]\n",
            "\n",
            "============================================================\n",
            "GENERANDO CON MODELO EDITADO (DESPUÉS DE ROME)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "COMPARACIÓN: ANTES VS DESPUÉS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Prompt 1: ¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?\n",
            "Target esperado: Juramento para casarse con Aconcio\n",
            "============================================================\n",
            "\n",
            "ANTES:\n",
            " ¿Qué papel jugó en la historia de Grecia?\n",
            "\n",
            "La leyenda de Cidipe se encuentra en la mitología griega y se refiere a la historia de Cidipe, un rey de Tebas que se enamoró de su hija, Cidonia. La leyenda cuenta que Cidipe se enamoró de Cidonia después de beber un vino envenenado por el dios Dioniso, lo que le hizo olvid\n",
            "\n",
            "DESPUÉS:\n",
            " Juramento para casarse con Aconcio. Juramento para casarse con Aconcio. Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconcio Juramento para casarse con Aconc ✅\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "PRUEBA CON TEMPERATURA ALTA (1.0)\n",
            "============================================================\n",
            "\n",
            "5 intentos por cada prompt:\n",
            "\n",
            "1. ¿Qué leyó Cidipe en voz alta en el contexto de la mitología griega?\n",
            "   Target: Juramento para casarse con Aconcio\n",
            "   1.  Juramento para casarse con Aconcio. Juramento para casarse ✅\n",
            "   2.  Juramento para casarse con Aconcio, aunque esto llevó a ✅\n",
            "   3.  Juramento para casarse con Aconcio\n",
            "\n",
            "Juramento de Jurisd ✅\n",
            "   4.  Juramento para casarse con Aconcio.\n",
            "¿Qué leyó Jur ✅\n",
            "   5.  Juramento para casarse con Aconcio.\n",
            "Juramento para casarse ✅\n",
            "\n",
            "============================================================\n",
            "RESUMEN\n",
            "============================================================\n",
            "\n",
            "Ediciones exitosas: 1/1 (100%)\n"
          ]
        }
      ]
    }
  ]
}